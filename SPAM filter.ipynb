{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify SPAM messages\n",
    "--------------------------\n",
    "We will use a public set of SMS labeled messages that have been collected for mobile phone spam research to classify new messages as spam or ham using multinomial Naive Bayes algorithm.\n",
    "\n",
    "The data set contains 2 columns.\n",
    "- Label: Which classifies a message as *spam* or *ham*\n",
    "- SMS: Actual content of the message\n",
    "\n",
    "More information on the collection process can be found [here](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/) and dataset can be downloaded from [here](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#settings\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label                     SMS\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read tab delimited data\n",
    "data = pd.read_csv(\"SMSSpamCollection\", sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "\n",
    "data.head()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5572 rows with 2 columns. As mentioned earlier the lable column has two classes 747 rows with \"spam\" and 4825 rows with \"ham\" values. There are no null or NA values. So we are good to build a learning model.\n",
    "\n",
    "Let's split the data set into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      " ham     86.53803\n",
      "spam    13.46197\n",
      "Name: Label, dtype: float64\n",
      "test set\n",
      " ham     86.816143\n",
      "spam    13.183857\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#randomize data set\n",
    "data_randomized = data.sample(frac=1, random_state=1)\n",
    "\n",
    "#split data to train and test\n",
    "split_row = int(data.shape[0] * 0.8)\n",
    "train = data_randomized[0:split_row].reset_index(drop=True)\n",
    "test = data_randomized[split_row:].reset_index(drop=True)\n",
    "\n",
    "#Verify data\n",
    "print(\"training set\\n\",train['Label'].value_counts(normalize=True)*100)\n",
    "print(\"test set\\n\", test['Label'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have validated the sets to have equal proportions of data which important during testing process. Let's use the train set to train the model.\n",
    "\n",
    "First we will manully implement the multiclass Naive Bayes algorithm and later use the sklearn version.\n",
    "\n",
    "Let's do some data cleaning to extract required information from the data.\n",
    "- remove any punctuation characters (we keep only a-z, A-Z and 0-9)\n",
    "- convert everything to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          yep by the pretty sculpture\n",
       "1           yes princess are you going to make me moan\n",
       "2                           welp apparently he retired\n",
       "3                                               havent\n",
       "4    i forgot 2 ask Ã¼ all smth there s a card on da...\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['SMS'] = train['SMS'].str.replace('\\W', ' ', regex=True).str.strip().str.replace(' +', ' ', regex=True)\n",
    "train['SMS'] = train['SMS'].str.lower()\n",
    "\n",
    "train['SMS'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a vocabulary (a list with all unique words accross all messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split messages on space\n",
    "train['SMS'] = train['SMS'].str.split()\n",
    "\n",
    "#collect words from all messages and filter unique\n",
    "vocabulary = []\n",
    "for sms in train['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of all unique words accross all messages, we need a way to count number of times each word in the vocabulary appeared in each message. For this we shall create a new dataframe that contain a label column and a column for each unique word in the vocabulary with count as values for each message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty dictionary with all 0's as count for each word in each message\n",
    "word_counts_per_sms = {unique_word: [0] * len(train['SMS']) for unique_word in vocabulary}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>greet</th>\n",
       "      <th>grams</th>\n",
       "      <th>exterminator</th>\n",
       "      <th>hot</th>\n",
       "      <th>rcb</th>\n",
       "      <th>wud</th>\n",
       "      <th>arguing</th>\n",
       "      <th>prabu</th>\n",
       "      <th>fones</th>\n",
       "      <th>...</th>\n",
       "      <th>uv</th>\n",
       "      <th>dub</th>\n",
       "      <th>fne</th>\n",
       "      <th>iz</th>\n",
       "      <th>slice</th>\n",
       "      <th>mother</th>\n",
       "      <th>removal</th>\n",
       "      <th>lasagna</th>\n",
       "      <th>iphone</th>\n",
       "      <th>under</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label  greet  grams  exterminator  hot  rcb  wud  arguing  prabu  fones  \\\n",
       "0   ham      0      0             0    0    0    0        0      0      0   \n",
       "1   ham      0      0             0    0    0    0        0      0      0   \n",
       "2   ham      0      0             0    0    0    0        0      0      0   \n",
       "3   ham      0      0             0    0    0    0        0      0      0   \n",
       "4   ham      0      0             0    0    0    0        0      0      0   \n",
       "\n",
       "   ...  uv  dub  fne  iz  slice  mother  removal  lasagna  iphone  under  \n",
       "0  ...   0    0    0   0      0       0        0        0       0      0  \n",
       "1  ...   0    0    0   0      0       0        0        0       0      0  \n",
       "2  ...   0    0    0   0      0       0        0        0       0      0  \n",
       "3  ...   0    0    0   0      0       0        0        0       0      0  \n",
       "4  ...   0    0    0   0      0       0        0        0       0      0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the actual counts\n",
    "for index, sms in enumerate(train['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "        \n",
    "#create new dataframe\n",
    "train_clean = pd.concat([train['Label'], pd.DataFrame(word_counts_per_sms)], axis=1)\n",
    "\n",
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a data set to work with let's create few terms which we will use in the Naive Bayes algorithm.\n",
    "\n",
    "- **p_spam**: probability of a message being spam\n",
    "- **p_ham**: probability of a message being ham\n",
    "- **n_spam**: number of words (all words, not just unique) in spam messages\n",
    "- **n_ham**: number of words (all words, not just unique) in ham messages\n",
    "- **n_vocabulary**: number of unique words accross all messages\n",
    "- **alpha**: Laplace smoothing which will be set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate probabilities\n",
    "p_spam = train_clean['Label'].value_counts(normalize=True)['spam']\n",
    "p_ham = train_clean['Label'].value_counts(normalize=True)['ham']\n",
    "\n",
    "#calculate counts\n",
    "n_spam = train_clean[train_clean['Label'] == 'spam'].sum(axis=1).sum()\n",
    "n_ham = train_clean[train_clean['Label'] == 'ham'].sum(axis=1).sum()\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to calculate probability of a word given message is spam and ham. So for each word we will calculate:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "The fact that this calculation is done before hand makes this algorithm perform really fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create two empty dictionaries with probabilities of each word\n",
    "p_words_spam = {word: 0 for word in vocabulary}\n",
    "p_words_ham = {word: 0 for word in vocabulary}\n",
    "\n",
    "#split data into spam and ham\n",
    "train_spam = train_clean[train_clean['Label'] == 'spam']\n",
    "train_ham = train_clean[train_clean['Label'] == 'ham']\n",
    "\n",
    "#calculate probabilites\n",
    "for word in vocabulary:\n",
    "    #calculate total number times this word appeared in messages\n",
    "    n_word_spam = train_spam[word].sum()\n",
    "    n_word_ham = train_ham[word].sum()\n",
    "    \n",
    "    #calculate probabilites\n",
    "    p_word_spam = (n_word_spam + alpha)/(n_spam + (alpha * n_vocabulary))\n",
    "    p_word_ham = (n_word_ham + alpha)/(n_ham + (alpha * n_vocabulary))\n",
    "    \n",
    "    #append to dictionaries\n",
    "    p_words_spam[word] += p_word_spam\n",
    "    p_words_ham[word] += p_word_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam probabilites\n",
      "greet: 8.706251088281386e-05\n",
      "grams: 4.353125544140693e-05\n",
      "exterminator: 4.353125544140693e-05\n",
      "\n",
      "ham probabilites\n",
      "greet: 4.614319772360224e-05\n",
      "grams: 3.076213181573483e-05\n",
      "exterminator: 3.076213181573483e-05\n"
     ]
    }
   ],
   "source": [
    "#print first 3 items in both dicts\n",
    "print(\"spam probabilites\")\n",
    "for key in list(p_words_spam)[0:3]:\n",
    "    print(\"{}: {}\".format(key, p_words_spam[key]))\n",
    "    \n",
    "print(\"\\nham probabilites\")\n",
    "for key in list(p_words_ham)[0:3]:\n",
    "    print(\"{}: {}\".format(key, p_words_ham[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the probabilities of all the words and others constants we need classify new messages.\n",
    "\n",
    "We will classify the message into three categories.\n",
    "- **spam**: if the probability of message being a spam is more\n",
    "- **ham**: if the probability of message being a ham is more.\n",
    "- **needs human classification**: if probabilities are equa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function that takes in a input string and classify the message\n",
    "def classify(message):\n",
    "    #clean and split the message\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().strip()\n",
    "    message = message.split()\n",
    "\n",
    "    #initiate values\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    #calculate spam and ham probabilities\n",
    "    for word in message:\n",
    "        if word in p_words_spam:\n",
    "            p_spam_given_message *= p_words_spam[word]\n",
    "        if word in p_words_ham:\n",
    "            p_ham_given_message *= p_words_ham[word]\n",
    "    \n",
    "    #return labels and probabilities\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have algorithm ready that can be used on test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wherre's my boytoy ? :-(</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham                           Wherre's my boytoy ? :-(       ham\n",
       "1   ham          Later i guess. I needa do mcat study too.       ham\n",
       "2   ham             But i haf enuff space got like 4 mb...       ham\n",
       "3  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "4   ham  All sounds good. Fingers . Makes it difficult ...       ham"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new column with predicted values\n",
    "test['predicted'] = test['SMS'].apply(classify)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First few rows looks accurate. Let's calculate accuracy and display confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9874439461883409\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>ham</th>\n",
       "      <th>needs human classification</th>\n",
       "      <th>spam</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>962</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>970</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  ham  needs human classification  spam   All\n",
       "True                                                  \n",
       "ham        962                           1     5   968\n",
       "spam         8                           0   139   147\n",
       "All        970                           1   144  1115"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate accuracy\n",
    "print(\"Accuracy score:\", (test['Label']==test['predicted']).sum()/len(test))\n",
    "\n",
    "#confusion matrix\n",
    "confusion_matirx = pd.crosstab(test['Label'], test['predicted'], rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "confusion_matirx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achived an accuracy of 98.74% which is really high. Out of 1115 message our message filter incorrectly classified only 13 and 1 where human interaction is need.\n",
    "\n",
    "However, we need to be careful about the True ham messages being classified as spam. These are \"False negative\". We need to aim for 0 in this field. For this our \"True positive rate (Recall)\" should be 100%.\n",
    "\n",
    "In achiving this we might end up having more spam messages as ham which is still fine than blocing a ham message as spam. This is the trade-off we need to consider.\n",
    "\n",
    "\n",
    "### To be continued..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
